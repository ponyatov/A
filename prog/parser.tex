\chapter{Лексический и синтаксический анализ}

Очень часто в практике возникает необходимость работы с данными в текстовых
форматах\ --- plain text файлы, в которых в каком-либо формате\note{на языке
разметки, или DDL [D]ata [D]efinition [L]anguage}\ описаны данные. И от вас
требуется реализовать разбор такого файла, выделяя элементы данных, чтобы в
дальнейшем после их преобразования например записать текстовый файл в другом
формате.

В таком виде хранятся результаты расчетных программ, работащих в пакетном
режиме, данные с измерительных систем, поток данных с приемников GPS\note{протокол
NMEA 0183}, очень популярный мета-формат XML со всеми его частными случаями типа
HTML, XLIFF\ref{xliff}, OpenDocument, тексты программ для станков с ЧПУ,\ldots

С некоторыми хинтами точно так же можно работать и с бинарными файлами,
преобразовав их сначала в текстовую форму (в простейшем случае просто сделав hex
dump).

В некоторых случаях необходимо написание трансляторов форматов (текстовых)
данных, или даже интерпретаторов/компиляторов языков программирования.

Все эти техники будут кратко описаны в этой главе. Подробнее эти техники
рассмотрены в книгах, особенно стоит отметить талмуд
\textbf{DragonBook} \cite{dragonbook}.

\bigskip
\term{Лексический анализ}\ --- процесс программного разбора входной
последовательности символов\note{например, такой как исходный код на одном из
языков программирования} с целью получения на выходе последовательности
символов, называемых «токенами» (подобно группировке букв в словах). Группа символов
входной последовательности, идентифицируемая на выходе процесса как токен,
называется лексемой. В процессе лексического анализа производится распознавание
и выделение лексем из входной последовательности символов.

\section{Применение flex/bison для разбора текстовых форматов данных}

\section{Компилятор Паскаля}
