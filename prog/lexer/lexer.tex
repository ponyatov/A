\secrel{Лексический и синтаксический анализ}\secdown

Очень часто в практике возникает необходимость работы с данными в текстовых
форматах\ --- \termdef{plain text}{plain text} файлы, в которых в каком-либо
формате (на языке разметки, или \termdef{DDL}{DDL}: \termdef{[D]ata
[D]efinition [L]anguage}{Data Definition Language}) описаны данные. И от вас
требуется реализовать разбор такого файла, выделяя синтаксические структуры и
элементы данных, чтобы в дальнейшем после их преобразования например записать
текстовый файл в другом формате.

В таком виде хранятся результаты расчетных программ, работащих в пакетном
режиме, данные с измерительных систем, поток данных с приемников
GPS\note{протокол NMEA 0183}, очень популярный мета-формат XML со всеми его
частными случаями типа HTML, XLIFF\ref{xliff}, OpenDocument, тексты программ
для станков с ЧПУ,\ldots

С некоторыми хинтами точно так же можно работать и с бинарными файлами,
преобразовав их сначала в текстовую форму (в простейшем случае просто сделав hex
dump).

В некоторых случаях необходимо написание трансляторов форматов (текстовых)
данных, или даже интерпретаторов/компиляторов языков программирования.

\bigskip
Все эти техники с использованием стандартных утилит \prog{flex}\ и \prog{bison}\
будут кратко описаны в этой главе. Подробнее эти техники рассмотрены в
книгах\ref{lexlit}, особенно стоит отметить талмуд
\textbf{DragonBook}:

\bigskip

\label{exdragon}\cite{dragonbook} \textbf{Книга Дракона}: Ахо, Сети, Ульман
Принципы построения компиляторов.

\bigskip

\href{http://habrahabr.ru/post/99162/}{Habr: Компиляция. 1: лексер}

\href{http://habrahabr.ru/post/99298/}{Habr: Компиляция. 2: грамматики}

\href{http://habrahabr.ru/post/99366/}{Habr: Компиляция. 3: бизон}

\href{http://habrahabr.ru/post/99397/}{Habr: Компиляция. 4: игрушечный ЯП}

\href{http://habrahabr.ru/post/99466/}{Habr: Компиляция. 5: нисходящий разбор}

\href{http://habrahabr.ru/post/102597/}{Habr: Компиляция. $5\frac{1}{2}$: llvm
как back-end}

\href{http://habrahabr.ru/post/99592/}{Habr: Компиляция. 6: промежуточный код}


\secrel{Лексер и лексический анализ, утилита \prog{flex}}

\begin{framed}
\noindent
\termdef{Л\'{е}ксер}{лексер}\ --- программа или ее часть, которая
\begin{enumerate}[nosep]
  \item
получает на вход исходные
данные в виде сплошного потока одиночных сиволов,
  \item
группирует символы согласно
набору правил (заданных \termdef{регулярными выражениями}{регулярное
выражение}) и
  \item
отдает на выходе символы, уже сгруппированные в \termdef{лекс\'{е}мы}{лексема}\
или \termdef{ток\'{е}ны}{токен}.
\end{enumerate}
Цель лексера\ --- подготовить последовательность лексем для входа другой
программы. \\
В самый простых случаях на лексер можно возложить простые преобразования текста.
\end{framed}

\termdef{Лексический анализ}{лексический анализ}\ --- процесс программного
разбора входной последовательности символов\note{например, такой как исходный
код на одном из языков программирования} с целью получения на выходе
последовательности групп символов\ --- \term{токенов}, имеющих собственное
смысловое значение\note{подобно группировке букв в слово}. Как правило,
лексический анализ производится в соответствии набора правил определённого
\term{формального, искуственного или компьютерного языка}.

\begin{framed}
\term{Компьютерный язык}, а точнее его \termdef{грамматика}{грамматика}, задаёт
определённый набор лексем, которые могут встретиться на входе лексера, и набор
правил, по которым их следует группировать.
\end{framed}

Традиционно принято организовывать процесс лексического анализа, рассматривая
входную последовательность символов как поток одиночных символов. При такой
организации \term{лексер}\ самостоятельно управляет выборкой отдельных символов
из входного потока.

Распознавание лексем с учетом грамматики обычно производится путём их
идентификации согласно идентификаторам токенов, определяемых грамматикой языка.
При этом любая последовательность символов входного потока (лекс\'{е}ма),
которая согласно грамматике не может быть идентифицирована как токен языка,
обычно рассматривается как специальный \term{токен-ошибка}.

\bigskip
Каждый выделенный токен можно представить в виде парной структуры,
содержащей
\begin{enumerate}
  \item идентификатор токена и
  \item саму последовательность символов лексемы, выделенной из входного
потока\note{запись строки, числа и т. д.}.
\end{enumerate}

\bigskip
Рассморим обработку текстового файла: разделение текстового фрагмента на абзацы,
запись в формате
\href{http://docs.oasis-open.org/xliff/xliff-core/xliff-core.html}{XLIFF} для
перевода в системе \href{http://smartcat.pro}{ABBYY SmartCAT}, и обратной
трансляции из XLIFF в \LaTeX-совместимое форматирование. 

\secrel{Генератор синтаксических анализаторов \prog{bison}}

\secrel{Дополнительная литература}\label{lexlit}

\bigskip

\url{http://alumni.cs.ucr.edu/~lgao/teaching/flex.html}

\secrel{Транслятор Паскаля}

\secrel{LLVM и разработка собственных компиляторов}

\secup
